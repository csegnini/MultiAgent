https://github.com/csegnini/MultiAgent
Hi i want to do some data analysis about Industrial Production and coffee web searches in the year 2024 at US

## Project Workflow

This project is a multi-agent system designed for the automated collection, analysis, and simplification of economic and web trend time series data. The workflow is orchestrated through a main `OrchestratorAgent` and is divided into three main phases, each handled by a specialized agent:

### 1. FRED Agent: Economic Data Retrieval

- **Input**: A set of keywords related to an economic topic (e.g., "Industrial Production").
- **Process**:
  - The agent uses a local mapping of keywords to FRED category IDs to find relevant economic data categories.
  - It then queries the FRED API to download the time series data corresponding to those categories for a specified time frame.
  - It then aggregates or disaggrates the time series to match a 'target frequency'(by default monthly) for example quaterly data to monthly or monthly to annual.
- **Output**: A CSV file containing the raw economic data (e.g., `fred_data_Industrial_Production.csv`).

### 2. Trends Agent: Web Search Data Retrieval

- **Input**: A list of search keywords (e.g., "Industrial Production", "coffee").
- **Process**:
  - The agent connects to the Google Trends service via an API.
  - It fetches the daily or weekly search interest data for the given keywords and geographic region.
  - The data is then aggregated into a monthly time series to align with the economic data.
- **Output**: A CSV file containing the monthly Google Trends data (e.g., `google_trends_data.csv`).

### 3. Modeling Agent: Analysis and Simplification

- **Input**: The file paths of the two CSVs generated by the FRED and Trends agents.
- **Process**: This agent runs a full, automated pipeline to process and analyze the data:
  1.  **Join Dataframes**: The two datasets are merged into a single time series dataframe.
  2.  **Impute Data**: A custom seasonal imputation algorithm fills in any missing data points.
  3.  **Calculate Change**: The data is converted to period-over-period percentage change to normalize it.
  4.  **All-Pairs Parallelism Score**: Every time series is compared against every other series to calculate a "parallelism score," which measures how similarly they move over time.
  5.  **Generate Joining Work Order**: Based on the scores, a work order is created that groups highly parallel series together.
  6.  **Join and Simplify**: The series in each group are averaged, simplifying the dataset into its core components.
- **Final Analysis**: On this final, simplified dataset, the agent can perform a **Correlation Analysis**, generating a correlation matrix and a visual heatmap to show the relationships between the simplified data components.
- **Output**: A final, simplified CSV file and a PNG image of the correlation heatmap.
